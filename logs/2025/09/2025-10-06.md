## 🧠 まず「scikit-learn」とは？

> **AI（機械学習）の基本操作を超カンタンにやらせてくれる“道具箱”**。

* 「Python（パイソン）」の中に「scikit-learn（サイキットラーン）」という“便利な機械学習キット”がある。

つまり

> 自分で数式を書く代わりに、`scikit-learn`に「データを渡して、学習して」と言うだけで、AIがパターンを覚えてくれる。

---

## 🍰 データの2種類：「特徴量」と「目的変数」

### 1️⃣ 特徴量（Feature / X）

> AIが「判断材料」として見る情報のこと。

たとえば：

| 年齢 | 年収   | 既婚  | 残業時間 | … |
| -- | ---- | --- | ---- | - |
| 28 | 400万 | いいえ | 10   | … |

→ これが「**特徴量 X**」。
人間で言うなら、「相手を観察して判断するための材料」。

---

### 2️⃣ 目的変数（Target / y）

> AIが「答え」として学ぶもの。

例えば「この人は1年以内に退職するか？」というラベル（0=続ける、1=辞める）が目的変数。

| 年齢 | 年収   | 既婚  | 残業時間 | **退職（目的変数）** |
| -- | ---- | --- | ---- | ------------ |
| 28 | 400万 | いいえ | 10   | **1**        |
| 42 | 600万 | はい  | 20   | **0**        |

---

### 💬 まとめると：

> **特徴量 (X)**：判断に使う材料
> **目的変数 (y)**：AIが予測したい「答え」

AIは「Xからyを予測できるように学ぶ」＝**これが“学習”**。

---

## 🔮 「回帰」「分類」とは？

AIの“予測の種類”のこと。
大きく2パターンだけ覚えればOK。

---

### 🟢 回帰（Regression）＝数値を予測する

> 「いくら？」「どのくらい？」を予測する。

📘 例：

* 家の広さ → 家賃を予測（10万円とか）
* 広告クリック率 → クリック確率を予測（0.18とか）

出てくる答えが **数字**。

🧩 scikit-learnでは：

```python
from sklearn.linear_model import LinearRegression
```

みたいな感じで“回帰モデル”を使う。

---

### 🔵 分類（Classification）＝グループを予測する

> 「どっち？」「どのカテゴリ？」を判定する。

📘 例：

* メール → スパム or 普通
* ユーザー → 解約 or 継続
* 写真 → 猫 or 犬

出てくる答えが **カテゴリー（ラベル）**。

🧩 scikit-learnでは：

```python
from sklearn.linear_model import LogisticRegression
```

みたいな“分類モデル”を使う（名前は回帰っぽいけど分類用）。

---

## ⚖️ 「混同行列」とは？

> モデルの“当てた・外した”を表にした診断ツール。

---

### 🧩 例：AIに「この人は解約する？」と予測させたとき

| 実際       | 予測       | 意味                       |
| -------- | -------- | ------------------------ |
| 解約した（1）  | 解約する（1）  | ✅ 正解（TP：True Positive）   |
| 解約した（1）  | 解約しない（0） | ❌ 見逃し（FN：False Negative） |
| 解約しない（0） | 解約する（1）  | ❌ 勘違い（FP：False Positive） |
| 解約しない（0） | 解約しない（0） | ✅ 正解（TN：True Negative）   |

---

### 👀 混同行列の見方

```
             予測=1   予測=0
実際=1       TP       FN
実際=0       FP       TN
```

AIが

* どのくらい**正しく当てているか**
* どのくらい**間違えているか**
* どんな方向に**偏って間違っているか**

を一目でわかるようにした表。

---

### 🧭 なんのために使うの？

モデルの「クセ」を把握するため。

たとえば：

* FP（偽陽性）が多い →「誤報が多い」→ 不要な対応コストが増える
* FN（偽陰性）が多い →「見逃しが多い」→ 解約者を取り逃す

→ だから、混同行列を見ると、**どんなミスをしてるAIか**がわかる。
単なる「正解率」よりずっと実用的。

---

## 📈 ここまでのまとめ

| 用語           | 意味                     | 例               |
| ------------ | ---------------------- | --------------- |
| scikit-learn | 機械学習を簡単にできるPythonライブラリ | 「AIの箱」みたいなもの    |
| 特徴量 (X)      | 判断材料になる情報              | 年齢、収入、残業時間など    |
| 目的変数 (y)     | AIが当てたい答え              | 解約する(1)・しない(0)  |
| 回帰           | 数字を予測する                | 売上、家賃、温度など      |
| 分類           | グループを予測する              | スパム or 非スパムなど   |
| 混同行列         | モデルの当たり・外れを表で可視化       | TP/FP/FN/TNの4区分 |

---

## 💬 一文でまとめると

> scikit-learnは、「データの特徴量（材料）」から「目的変数（答え）」を学び、
> 回帰なら“数字”、分類なら“グループ”を予測し、
> 混同行列で「どのくらい当たったか・どんな外し方をしたか」を分析する道具。
