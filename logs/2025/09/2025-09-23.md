# 🔹9/23タスク：前処理Notebookリファイン

(実務上求められる部分メモ)
## 1. コメント追記（読みやすさ＝実務力）

実務で求められるのは「他人が見てすぐ理解できるコード」。
→ 企業ではレビューや引き継ぎが頻繁だから、**「自分が3ヶ月後に忘れても理解できる」レベル**でコメントを書くのが基準。

* コメントは「なぜこの処理が必要か」を説明する。
  ❌ `# 欠損値処理`
  ⭕ `# Age列の欠損は中央値で補完（平均だと外れ値に影響されやすいため）`

📌 実務Tips：
「**WhatよりWhyを説明**」──これでレビューが通りやすい。

---

## 2. 可視化追加（EDA＝データ理解の基礎）

EDA（探索的データ分析）は、実務でも「最初にどこまでデータを理解したか」で成果が変わる。
Notebookに入れると良いグラフは以下：

* **分布**：`sns.histplot(df['Age'])`
  → 年齢の分布を直感的に把握。
* **カテゴリごとの比率**：`sns.countplot(x='Sex', data=df)`
  → 男性/女性の偏りを確認。
* **相関関係**：`sns.heatmap(df.corr(), annot=True)`
  → 特徴量同士の関係性を把握。

📌 実務Tips：
可視化は「ストーリー」にする。つまり、単発ではなく
「この変数は偏っている → 欠損処理方針に繋がる」
と一連の流れで語れるようにしておく。

---

## 3. Notebook全体の整理

* Notebook冒頭に「データ概要」をコメントで書く（例：行数、列数、対象はTitanicの生存予測）。
* 各セクションに「見出しコメント」を入れる（例：`# 1. データ読込 / # 2. 欠損処理 / # 3. 可視化`）。

📌 実務Tips：
企業ではNotebookをそのままレビューに出すこともある。**見出しを章立て**にしておくと、読みやすさが一気に上がる。

---

# 🔹用語の整理

### 1. Titanic（タイタニック）

* Kaggle（データ分析の練習サイト）の有名な「練習用データセット」。
* 1912年に沈没したタイタニック号の乗客データで、
  **「生き残ったかどうか（Survived列）」を予測する**ことが目的。
* 列の例：年齢（Age）、性別（Sex）、客室クラス（Pclass）、料金（Fare）、生存（Survived）。

---

### 2. 前処理（Preprocessing）

* 生のデータはそのままだと欠損やバラツキが多くて使いにくい。
* だから機械学習に使えるように「整理」する作業をする。
  例：

  * 欠損（空欄）のデータを埋める
  * 文字を数字に変える（男=0、女=1みたいに）
  * 数値が偏っていたら調整する

---

### 3. EDA（Exploratory Data Analysis：探索的データ分析）

* 簡単に言えば \*\*「グラフでデータを眺めて、特徴をつかむ」\*\*こと。
* 例えば：

  * 年齢の分布をヒストグラムにする → 若い人が多いか、高齢が多いかを知る
  * 男女の人数を棒グラフにする → 男性の方が多いか？
  * 料金（Fare）が生存率に関係していそうか？

👉 「どんなデータか」を直感でつかむためにグラフを作る。

---

# 🔹今日やること（9/23）

1. **Notebookの最初に「概要の説明」を書く**

2. **グラフを2つ作る**（最低限）

   * 年齢の分布（ヒストグラム）
   * 男女の人数（棒グラフ）

3. **コードに理由をコメントする**

   * 例：

     ```python
     # Age列は欠損があるため、中央値で埋める（平均だと外れ値に影響されやすいから）
     df["Age"] = df["Age"].fillna(df["Age"].median())
     ```

---

# Notebook冒頭に入れる「概要」

```markdown
# 目的
このノートブックは、Titanic（タイタニック号の乗客データ）を使って、
機械学習用に使いやすくするための「前処理」と「データを理解するための簡単なグラフ」を作る。

# データの中身（ざっくり）
- 行数と列数: 891行 × 12列（train.csv想定）
- 重要な列: Survived(生存0/1), Age(年齢), Sex(性別), Pclass(客室クラス), Fare(料金)
- 目的列: Survived（これを将来モデルで予測したい）

# 今日やること
1) 欠損の確認と簡単な補完（例：Ageは中央値で埋める）
2) グラフで全体を把握（年齢の分布、男女の人数）
3) 変換の理由をコメントで残す（なぜその処理をするのか）

# 出力（後で再利用できる形）
- 前処理後のCSV: cleaned_titanic.csv
- 参考図: figs/age_hist.png, figs/sex_count.png
```

# セクション見出し（章立て）も先に置く（コピペ）

```markdown
# 1. データ読込
# 2. データの状態確認（欠損・型・ざっくり統計）
# 3. 可視化で全体をつかむ（EDA）
# 4. 前処理（欠損補完・変換）
# 5. 前処理後のデータを書き出し
```

---

# Kaggle からTitanic をダウンロード。

---

## 🔹入手方法（公式）

1. Kaggle アカウントを作成（無料）
   👉 [Kaggle Titanicページ](https://www.kaggle.com/c/titanic/data)
2. 「Download All」からZIPをダウンロード
3. ZIPを解凍すると `train.csv` と `test.csv` が出てくる

   * 今回は **`train.csv`** を使う。

> 保存場所は、いま作業しているフォルダ
> `C:\Users\chino\pystudy\python-data-preprocessing\`
> に置く。

---

# コード

```python
import pandas as pd

# 1. データ読込
df = pd.read_csv("train.csv")

# 先頭を表示して列名・値の雰囲気を確認
df.head()
```

```python
# 2. データの状態確認（欠損・型・ざっくり統計）

# 1) データ全体の形（行数・列数）
print("行数・列数:", df.shape)

# 2) 欠損（空欄）の数を列ごとに確認
print("\n欠損数（多い順）:")
print(df.isna().sum().sort_values(ascending=False))

# 3) 各列のデータ型（int, float, object など）
print("\nデータ型:")
print(df.dtypes)

# 4) 数値列の統計量（平均・中央値・最小・最大など）
print("\n数値列の統計量:")
print(df.describe())

# 5) 文字列（カテゴリ）列の概要
print("\nカテゴリ列のユニーク数:")
print(df.select_dtypes(exclude=["number"]).nunique())
```

上記の結果は下記だった。
```
行数・列数: (891, 12)

欠損数（多い順）:
Cabin          687
Age            177
Embarked         2
PassengerId      0
Name             0
Pclass           0
Survived         0
Sex              0
Parch            0
SibSp            0
Fare             0
Ticket           0
dtype: int64

データ型:
PassengerId      int64
Survived         int64
Pclass           int64
Name            object
Sex             object
Age            float64
SibSp            int64
Parch            int64
Ticket          object
Fare           float64
Cabin           object
Embarked        object
dtype: object

数値列の統計量:
       PassengerId    Survived      Pclass         Age       SibSp  \
count   891.000000  891.000000  891.000000  714.000000  891.000000   
mean    446.000000    0.383838    2.308642   29.699118    0.523008   
std     257.353842    0.486592    0.836071   14.526497    1.102743   
min       1.000000    0.000000    1.000000    0.420000    0.000000   
25%     223.500000    0.000000    2.000000   20.125000    0.000000   
50%     446.000000    0.000000    3.000000   28.000000    0.000000   
75%     668.500000    1.000000    3.000000   38.000000    1.000000   
max     891.000000    1.000000    3.000000   80.000000    8.000000   

            Parch        Fare  
count  891.000000  891.000000  
mean     0.381594   32.204208  
std      0.806057   49.693429  
min      0.000000    0.000000  
25%      0.000000    7.910400  
50%      0.000000   14.454200  
75%      0.000000   31.000000  
max      6.000000  512.329200  

カテゴリ列のユニーク数:
Name        891
Sex           2
Ticket      681
Cabin       147
Embarked      3
dtype: int64
```

## 🔹列ごとの状況と扱い方

### 1. 欠損の多い列

* **Cabin**（687/891 欠損）

  * ほとんど空欄。細かい部屋番号を使うのは無理。
  * → **「Cabinが記録されているかどうか（有無）」だけを0/1に変える**のが現実的。
 
* **Age**（177欠損）

  * 欠損は2割弱。平均や中央値で埋めれば十分。
  * → **中央値で埋める**（外れ値に強いから）。
    
* **Embarked**（2欠損）

  * 2つだけなら、もっとも多い値（mode=最頻値）で埋めてしまう。

* **平均や中央値で埋める理由**
  → たとえば「Age」の欠損が2割くらいあっても、残り8割のデータがあるから全体の傾向は見えている。
  → 平均は外れ値に弱い（例：一人だけ200歳みたいな値があると平均がズレる）。
  → 中央値は外れ値の影響を受けにくい。だから実務では **中央値がよく選ばれる**。

* **欠損が数件しかない場合**
  → Embarkedみたいに「たった2件だけ欠損」なら、最頻値（よく出る値）で埋めても全体の傾向は変わらない。
  → 「おそらくその人も一番多いグループに属していたはず」と仮定できる。

👉 まとめると：

* 欠損がそこそこある数値列 → **中央値**
* 欠損がごくわずか＆カテゴリ列 → **最頻値**

---

### 2. 文字列（カテゴリ）の列

* **Sex**：男女の2値 → 数値化（例：female=1, male=0）
* **Embarked**：港（3種類） → one-hotエンコード（S, C, Q をダミー変数に）
* **Name**：名前はユニークなので学習にはそのまま不要
* **Ticket**：ほとんどがバラバラ → 使わない

Embarkedとは？

* 意味：**どの港から船に乗ったか**
* タイタニックには大きく3つの港があった：

  * **S (Southampton)** イギリス南部サウサンプトン港 → 乗客が最も多い
  * **C (Cherbourg)** フランス・シェルブール港
  * **Q (Queenstown)** アイルランド・クイーンズタウン港

👉 つまり、`Embarked` 列は **「乗船した港の種類」** を表している。

one-hotエンコードとは？

* 機械学習は「文字」を直接理解できない → **数字に変換する必要がある**。
* でも単純に「S=0, C=1, Q=2」と数字を割り当てると、**数字に順序があるように誤解されてしまう**（2は1より大きい＝QがCより上？と誤解される）。

そこで使うのが **one-hotエンコード**：

* `Embarked` の値が

  * S → `[1, 0, 0]`
  * C → `[0, 1, 0]`
  * Q → `[0, 0, 1]`

列を3本に分けて、それぞれ「その港かどうか」を 0/1 で表す。

例：

```
Embarked_S  Embarked_C  Embarked_Q
1           0           0   ← Southamptonから乗船
0           1           0   ← Cherbourgから乗船
0           0           1   ← Queenstownから乗船
```

👉 これなら「港に順位がある」と誤解されない。実務ではカテゴリ変数はほとんどこの処理をする。

---

### 3. 数値列

* **Fare**：最大512と高い外れ値あり（平均32と比べて突出）。

  * → とりあえずはそのまま使う（外れ値処理は応用編）。
* **Pclass, SibSp, Parch**：整数。客室クラスや家族人数なので有効。

---

## 🔹前処理の方針（まとめ）

1. **欠損埋め**

   * Age → 中央値で埋める
   * Embarked → 最頻値で埋める
   * Cabin → 「Cabinがあるかどうか」を新しい列にする（0/1）

2. **文字列の変換**

   * Sex → female=1, male=0
   * Embarked → one-hot化（S, C, Q）

3. **不要列**

   * Name, Ticket, PassengerId → 削除（今回の練習では）

---

```python
import matplotlib.pyplot as plt

# 年齢の分布（ヒストグラム）どの年代が多いか、外れ値はあるかを把握する。
plt.hist(df["Age"].dropna(), bins=30, color="skyblue", edgecolor="black")
plt.title("Age distribution")
plt.xlabel("Age")
plt.ylabel("Count")
plt.show()

# 男女の人数（棒グラフ）男性と女性の人数の差（データの偏り）を確認する。
df["Sex"].value_counts().plot(kind="bar", color=["lightcoral", "lightblue"])
plt.title("Sex count")
plt.xlabel("Sex")
plt.ylabel("Count")
plt.show()
```
<img width="747" height="569" alt="image" src="https://github.com/user-attachments/assets/c4114e3c-f0eb-4467-9f15-f0dcadc2b048" />
<img width="757" height="624" alt="image" src="https://github.com/user-attachments/assets/b6e70504-7a1c-4140-930f-0c9c76648148" />

上記のコードにより表示されたグラフから読み解けること(EDA)

---

## 🔹 年齢の分布（Age distribution）

* **20歳付近が最も多い** → 若い乗客が中心。
* **0歳〜子どももいる** → 家族で乗船していた人も多いと推測できる。
* **40代以降は少なくなる** → 高齢の乗客は少数派。
* 外れ値（70〜80歳くらい）が少数ある → モデルで扱うときに影響を受ける可能性がある。

**実務的ポイント**

* 「平均年齢で埋める」より「中央値」で埋めた方が安全そう。
* 年齢は将来のモデルに「サバイバル率との関係」を分析する重要な特徴になる。

---

## 🔹 男女の人数（Sex count）

* **男性：約577人、女性：約314人** → 男性の方が多い。
* データが偏っていることが分かる。

**実務的ポイント**

* 機械学習モデルはデータの「偏り」をそのまま学習してしまう。
* 男女比の違いを踏まえて「サバイバル率の違い」を見ると、Titanicの場合はかなり有名な「女性の方が生存率が高い」という傾向が確認できる。

---


```python
# 4. 前処理（欠損補完・変換・出力）

import pandas as pd

# ===== ① 欠損を埋める =====
# Age：外れ値に強い中央値で埋める
df["Age"] = df["Age"].fillna(df["Age"].median())

# Embarked：欠損は2件だけ→最頻値で埋める
df["Embarked"] = df["Embarked"].fillna(df["Embarked"].mode()[0])

# Cabin：詳細は欠損だらけ→「記録があるか」を0/1化
df["HasCabin"] = df["Cabin"].notna().astype(int)

# ===== ② 文字を数値へ =====
# Sex：female=1, male=0（2値）
df["Sex_female"] = (df["Sex"] == "female").astype(int)

# Embarked：順序を持たせないため one-hot（S/C/Q をそれぞれ列に）
emb = pd.get_dummies(df["Embarked"], prefix="Embarked", dtype=int)
df = pd.concat([df, emb], axis=1)

# ===== ③ 使わない列を落とす（今回の練習では）=====
drop_cols = ["Name", "Ticket", "Cabin", "PassengerId", "Sex", "Embarked"]
df_clean = df.drop(columns=drop_cols)

# ===== ④ 保存（あとで学習に使える形）=====
df_clean.to_csv("cleaned_titanic.csv", index=False)
print("saved:", "cleaned_titanic.csv")

# 確認
print(df_clean.head())
print("shape:", df_clean.shape)
```



