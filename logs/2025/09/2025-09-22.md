「**ポートフォリオになるNotebook**」を作る。
今日は「公開用に仕上げる」のが目的。

---

## 📘 今日の進め方（9月22日）

1. **Notebookタイトルをつける**

   * 一番上のセルを Markdown にして、こう書く：

   ```markdown
   # Pythonによるデータ前処理入門
   - NumPy・Pandas基礎
   - 簡単なデータ前処理例
   ```

2. **イントロ説明を書く（Markdownセル）**

   ```markdown
   このNotebookでは、Pythonのライブラリ NumPy・Pandas を使ったデータ前処理の基礎を実演します。  
   サンプルデータを作成し、欠損値の確認・補完、簡単な集計を行います。  
   ```

3. **ライブラリ読み込み**

   ```python
   import numpy as np
   import pandas as pd
   ```

4. **サンプルデータを作成**

   ```python
   df = pd.DataFrame({
       "name": ["Shino", "Mika", "Rin", None],
       "score": [95, 88, None, 72],
       "class": ["A", "B", "A", "B"]
   })
   df
   ```

5. **欠損値の確認**

   ```python
   df.info()
   df.isna().sum()
   ```

6. **欠損値の処理**

   ```python
   df_fill = df.copy()
   df_fill["name"] = df_fill["name"].fillna("Unknown")
   df_fill["score"] = df_fill["score"].fillna(df_fill["score"].mean())
   df_fill
   ```

7. **集計（クラスごとの平均点）**

   ```python
   df_fill.groupby("class")["score"].mean()
   ```

8. **まとめ（Markdownセル）**

   * 学んだことを整理：

   ```markdown
   - `info()`, `isna().sum()` で欠損を確認  
   - `fillna()` で欠損を補完（文字列は固定値、数値は平均値で補完）  
   - `groupby()` でカテゴリごとに集計  
   データ分析の前処理に必要な基本操作を学んだ。
   ```

---

👉 ここまで完成したら、それを **GitHubリポジトリに push** して公開する。

---

# 0) 前準備（今日のノート名を決める）

Notebookを `data_preprocessing_intro.ipynb` という名前で保存しておく。

ついでに **.gitignore** も作る（余計なゴミを上げないため）。
ローカルのターミナル（PowerShell / Anaconda Prompt / VSCodeのターミナル）に入力する。

```
# .gitignore
.ipynb_checkpoints/
__pycache__/
*.pyc
.DS_Store
.env
.vscode/
```

---

### 1.  `.gitignore` について

→ Git で **「このファイルはリポジトリに入れないで」** と指定するための設定ファイル。

例えば：

* `.ipynb_checkpoints/` → Jupyterが自動で作るバックアップ（邪魔）
* `__pycache__/`, `*.pyc` → Pythonが自動生成するキャッシュ（不要）
* `.DS_Store` → Macが勝手に作る隠しファイル（Windowsなら出ないけど一応書く）
* `.vscode/` → VS Codeの個人設定（他人に不要）

これを `.gitignore` に書いておくと、`git add .` してもそれらは無視される。
つまり、**本当に必要なノートブックやコードだけをGitHubにアップできる**。

---

## 🔹 手順
JupyterLab 上部メニュー → File → New → Terminal を開いて、次を実行
```
pwd                 # ここがノートのあるフォルダか確認
echo ".ipynb_checkpoints/" > .gitignore
echo "__pycache__/" >> .gitignore
echo "*.pyc" >> .gitignore
echo ".DS_Store" >> .gitignore
echo ".env" >> .gitignore
echo ".vscode/" >> .gitignore
```


---

# 1) フォルダでターミナルを開く

Notebookがあるフォルダをカレントにして、**Anaconda Prompt** か **PowerShell** を開く。
（JupyterLabの左上「Terminal」でもOK）

確認：

```bash
pwd
dir   # Windows
```

---

# 2) Git 初期化＆初コミット

```bash
git --version   # Gitが無ければ https://git-scm.com/ から入れる

git init
git branch -M main

# 初回だけ：ユーザー名・メール（Gitの履歴に載る）
git config user.name "Chino"
git config user.email "your-email@example.com"

git add .
git commit -m "Add notebook: data preprocessing with pandas (missing value handling + groupby)"
```

---

# 3) GitHub で空のリポジトリを作成

ブラウザで GitHub → **New repository** → 例えば
**`python-data-preprocessing`**（Public推奨）

> 重要：**READMEや.gitignoreは作らない（空のリポジトリ）**
> → ローカルと競合しないため

---

# 4) リモート登録 → push

GitHubが表示するURLを使って：

```bash
git remote add origin https://github.com/<あなたのユーザー名>/python-data-preprocessing.git
git push -u origin main
```

* 認証を聞かれたら：

  * Username：GitHubのユーザー名
  * Password：**パスワードではなく「個人アクセストークン（PAT）」**

    * GitHub > Settings > Developer settings > **Personal access tokens** > **Tokens(classic)**
    * “repo” にチェックして作成 → 表示されたトークンをコピペ

---

# 5) 公開後の確認

* リポジトリページを開くと **`.ipynb` はそのままレンダリング**される
* READMEを後で追加すると見栄えUP（Notebookの目的・実行方法・学んだことを数行）

READMEの雛形（任意）：

```markdown
# Data Preprocessing with Python (NumPy & Pandas)

This notebook demonstrates basic data preprocessing:
- Missing value inspection and imputation (`info`, `isna().sum()`, `fillna`)
- Simple aggregation by category (`groupby`, `mean`)

File: `data_preprocessing_intro.ipynb`
```

---

# 6) 次回の更新フロー（覚えておくと楽）

```bash
# 変更したら
git add -A
git commit -m "Update: add English comments and sorting by mean"
git push
```
