---
title: 2025-09-29 線形代数入門（行列・ベクトル）
---

## 1. 「線形代数」について

* **代数** = 数や記号を使って計算・ルールを扱う学問  
* **線形** = 直線的に増えたり組み合わせたりする性質  

つまり線形代数とは、  
➡️ **「ベクトル」や「行列」というものを使って、空間の形や関係を表す学問」**。  

ここで出てくる重要ワードは **ベクトル** と **行列**。

---

## 2. ベクトルとは？

例えば：

* 1次元のベクトル（ただの数）  
$ \begin{bmatrix}5\end{bmatrix} $

* 2次元のベクトル  
$ \begin{bmatrix}3\\4\end{bmatrix} $  
→ 「右に3、上に4」を意味する矢印（座標）。

* 3次元のベクトル  
$ \begin{bmatrix}1\\2\\3\end{bmatrix} $  
→ 空間上の点や矢印を表す。

**イメージ**：ベクトルは「矢印」「位置」「方向」を表す便利な道具。

---

## 3. 行列とは？

「ベクトルをまとめた表」＝ **数字の表（マス目）** のこと。

例：  
$ \begin{bmatrix}1 & 2\\3 & 4\end{bmatrix} $

これは「2行2列の行列」。  
もっと大きい表も：  
$ \begin{bmatrix}1 & 2 & 3\\4 & 5 & 6\end{bmatrix} $  
これは「2行3列の行列」。

**イメージ**：  
行列は「ベクトルを横に並べたもの」や「変換ルール（変身装置）」として使える。

---

## 4. ベクトルの足し算・掛け算

- **足し算**（同じ位置の数を足すだけ）

$$
\begin{bmatrix}3\\4\end{bmatrix}
+
\begin{bmatrix}1\\2\end{bmatrix}
=
\begin{bmatrix}4\\6\end{bmatrix}
$$

- **数との掛け算**（スカラー倍）

$$
2 \times
\begin{bmatrix}3\\4\end{bmatrix}
=
\begin{bmatrix}6\\8\end{bmatrix}
$$

➡️ 矢印が「伸びる／縮む／向きが変わらない」イメージ。

---

## 5. 行列とベクトルの掛け算

これが線形代数のキモ。  
行列は「変換装置」。ベクトルを入力すると、別のベクトルが出てくる。

例：

$$
\begin{bmatrix}
2 & 0\\
0 & 3
\end{bmatrix}
\begin{bmatrix}
1\\
2
\end{bmatrix}
=
\begin{bmatrix}
2\\
6
\end{bmatrix}
$$

意味：

* x方向は2倍  
* y方向は3倍  
➡️ 行列が「拡大・縮小・回転」みたいな働きをする。

---

## 6. なんで大事なのか

* **AI/機械学習**では、データはベクトルで表す  
  （例：ユーザーの行動を数値化 → ベクトルに）  
* ニューラルネットワークは「行列とベクトルの掛け算の繰り返し」  
  （例：入力データ → 行列変換 → 次の層へ → 最終的に予測）

つまり線形代数を理解すると、  
➡️ **AIの仕組みの“心臓部”を読めるようになる**。

---

## まとめ

* **ベクトル**＝矢印／データの入れ物  
* **行列**＝変換ルール（表形式）  
* **行列×ベクトル**＝ベクトルを変身させる
